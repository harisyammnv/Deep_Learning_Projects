{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Libraries\n",
    "Load required librarires"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# Load Libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import collections\n",
    "import nltk\n",
    "from keras.preprocessing import sequence\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pickle\n",
    "import os.path\n",
    "from keras.models import Sequential,load_model\n",
    "from keras.layers.core import Activation,Dense,Dropout,SpatialDropout1D\n",
    "from keras.layers.wrappers import Bidirectional\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras.layers.recurrent import LSTM,GRU\n",
    "from keras import regularizers\n",
    "from keras.callbacks import ModelCheckpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# load data\n",
    "train = pd.read_csv(\"train.csv\")\n",
    "test = pd.read_csv(\"test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>User_ID</th>\n",
       "      <th>Description</th>\n",
       "      <th>Browser_Used</th>\n",
       "      <th>Device_Used</th>\n",
       "      <th>Is_Response</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>id10326</td>\n",
       "      <td>The room was kind of clean but had a VERY stro...</td>\n",
       "      <td>Edge</td>\n",
       "      <td>Mobile</td>\n",
       "      <td>not happy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>id10327</td>\n",
       "      <td>I stayed at the Crown Plaza April -- - April -...</td>\n",
       "      <td>Internet Explorer</td>\n",
       "      <td>Mobile</td>\n",
       "      <td>not happy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>id10328</td>\n",
       "      <td>I booked this hotel through Hotwire at the low...</td>\n",
       "      <td>Mozilla</td>\n",
       "      <td>Tablet</td>\n",
       "      <td>not happy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>id10329</td>\n",
       "      <td>Stayed here with husband and sons on the way t...</td>\n",
       "      <td>InternetExplorer</td>\n",
       "      <td>Desktop</td>\n",
       "      <td>happy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>id10330</td>\n",
       "      <td>My girlfriends and I stayed here to celebrate ...</td>\n",
       "      <td>Edge</td>\n",
       "      <td>Tablet</td>\n",
       "      <td>not happy</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   User_ID                                        Description  \\\n",
       "0  id10326  The room was kind of clean but had a VERY stro...   \n",
       "1  id10327  I stayed at the Crown Plaza April -- - April -...   \n",
       "2  id10328  I booked this hotel through Hotwire at the low...   \n",
       "3  id10329  Stayed here with husband and sons on the way t...   \n",
       "4  id10330  My girlfriends and I stayed here to celebrate ...   \n",
       "\n",
       "        Browser_Used Device_Used Is_Response  \n",
       "0               Edge      Mobile   not happy  \n",
       "1  Internet Explorer      Mobile   not happy  \n",
       "2            Mozilla      Tablet   not happy  \n",
       "3   InternetExplorer     Desktop       happy  \n",
       "4               Edge      Tablet   not happy  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>User_ID</th>\n",
       "      <th>Description</th>\n",
       "      <th>Browser_Used</th>\n",
       "      <th>Device_Used</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>id80132</td>\n",
       "      <td>Looking for a motel in close proximity to TV t...</td>\n",
       "      <td>Firefox</td>\n",
       "      <td>Mobile</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>id80133</td>\n",
       "      <td>Walking distance to Madison Square Garden and ...</td>\n",
       "      <td>InternetExplorer</td>\n",
       "      <td>Desktop</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>id80134</td>\n",
       "      <td>Visited Seattle on business. Spent - nights in...</td>\n",
       "      <td>IE</td>\n",
       "      <td>Tablet</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>id80135</td>\n",
       "      <td>This hotel location is excellent and the rooms...</td>\n",
       "      <td>Edge</td>\n",
       "      <td>Mobile</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>id80136</td>\n",
       "      <td>This hotel is awesome I love the service Antho...</td>\n",
       "      <td>Mozilla</td>\n",
       "      <td>Mobile</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   User_ID                                        Description  \\\n",
       "0  id80132  Looking for a motel in close proximity to TV t...   \n",
       "1  id80133  Walking distance to Madison Square Garden and ...   \n",
       "2  id80134  Visited Seattle on business. Spent - nights in...   \n",
       "3  id80135  This hotel location is excellent and the rooms...   \n",
       "4  id80136  This hotel is awesome I love the service Antho...   \n",
       "\n",
       "       Browser_Used Device_Used  \n",
       "0           Firefox      Mobile  \n",
       "1  InternetExplorer     Desktop  \n",
       "2                IE      Tablet  \n",
       "3              Edge      Mobile  \n",
       "4           Mozilla      Mobile  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare Data\n",
    "prepare train data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "maxlen=0\n",
    "word_freqs=collections.Counter()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    The room was kind of clean but had a VERY stro...\n",
       "1    I stayed at the Crown Plaza April -- - April -...\n",
       "2    I booked this hotel through Hotwire at the low...\n",
       "3    Stayed here with husband and sons on the way t...\n",
       "4    My girlfriends and I stayed here to celebrate ...\n",
       "Name: Description, dtype: object"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_description=train[\"Description\"]\n",
    "train_description.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    Looking for a motel in close proximity to TV t...\n",
       "1    Walking distance to Madison Square Garden and ...\n",
       "2    Visited Seattle on business. Spent - nights in...\n",
       "3    This hotel location is excellent and the rooms...\n",
       "4    This hotel is awesome I love the service Antho...\n",
       "Name: Description, dtype: object"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_description=test[\"Description\"]\n",
    "test_description.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for sentence in train_description:\n",
    "    words=nltk.word_tokenize(sentence.lower())\n",
    "    if len(words)>maxlen:\n",
    "        maxlen=len(words)\n",
    "    for word in words:\n",
    "        word_freqs[word]+=1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3767, 64274)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "maxlen,len(word_freqs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "MAX_SENTENCE_LENGTH=500\n",
    "MAX_FEATURES=30000\n",
    "vocab_size=min(MAX_FEATURES,len(word_freqs))+2\n",
    "word2index={x[0]:i+2 for i,x in enumerate(word_freqs.most_common(MAX_FEATURES))}\n",
    "word2index[\"PAD\"]=0\n",
    "word2index[\"UNK\"]=1\n",
    "index2word={v:k for k,v in word2index.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30002"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0, 'PAD')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word2index[\"PAD\"],index2word[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['not_happy',\n",
       " 'not_happy',\n",
       " 'not_happy',\n",
       " 'happy',\n",
       " 'not_happy',\n",
       " 'happy',\n",
       " 'not_happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'not_happy']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_filename=\"X_train.p\"\n",
    "X_test_filename=\"X_test.p\"\n",
    "y_train_filename=\"y_train.p\"\n",
    "model_filename=\"model.h5\"\n",
    "\n",
    "def normalize(train_description):\n",
    "    X=np.empty((train_description.size,),dtype=list)\n",
    "    i=0\n",
    "    for sentence in train_description:\n",
    "        words=nltk.word_tokenize(sentence.lower())\n",
    "        seqs=[]\n",
    "        for word in words:\n",
    "            if word in word2index:\n",
    "                seqs.append(word2index[word])\n",
    "            else:\n",
    "                seqs.append(word2index[\"UNK\"])\n",
    "        X[i]=seqs\n",
    "        i+=1\n",
    "    return sequence.pad_sequences(X,maxlen=MAX_SENTENCE_LENGTH)\n",
    "\n",
    "def denormalize_response(predictions):\n",
    "    return ['happy' if x > 0.5  else 'not_happy' for x in predictions]\n",
    "\n",
    "def normalize_response(predictions):\n",
    "    return [1 if x == 'happy' else 0 for x in predictions]\n",
    "\n",
    "def load_data(force=False):\n",
    "    if os.path.exists(X_train_filename) and os.path.exists(X_test_filename) and os.path.exists(y_train_filename) and not force:        \n",
    "        X_train=pickle.load( open( X_train_filename, \"rb\" ) )\n",
    "        X_test=pickle.load( open( X_test_filename, \"rb\" ) )\n",
    "        y_train=pickle.load( open( y_train_filename, \"rb\" ) )\n",
    "    else:\n",
    "        X_train=normalize(train_description)\n",
    "        X_test=normalize(test_description)\n",
    "        y_train=normalize_response(train[\"Is_Response\"])\n",
    "        pickle.dump( X_train, open( X_train_filename, \"wb\" ))\n",
    "        pickle.dump( X_test, open( X_test_filename, \"wb\" ))\n",
    "        pickle.dump( y_train, open( y_train_filename, \"wb\" ))\n",
    "    return X_train,X_test,y_train\n",
    "\n",
    "X_train,X_test,y_train=load_data()\n",
    "denormalize_response(normalize_response(train[\"Is_Response\"]))[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Xtrain,Xtest,ytrain,ytest=train_test_split(X_train,y_train,test_size=0.3,random_state=40)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Model\n",
    "Train model on prepared data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 27252 samples, validate on 11680 samples\n",
      "Epoch 1/2\n",
      "27252/27252 [==============================] - 2943s - loss: 0.1954 - acc: 0.9263 - val_loss: 0.2636 - val_acc: 0.8932\n",
      "Epoch 2/2\n",
      "27252/27252 [==============================] - 2964s - loss: 0.1800 - acc: 0.9317 - val_loss: 0.2656 - val_acc: 0.8946\n"
     ]
    }
   ],
   "source": [
    "EMBEDDING_SIZE=128\n",
    "HIDDEN_LAYER_SIZE=64\n",
    "BATCH_SIZE=32\n",
    "NUM_EPOCHS=2\n",
    "DROPOUT=0.1\n",
    "\n",
    "def load_train_model(force=False):\n",
    "    if os.path.exists(model_filename) and not force:\n",
    "        model=load_model(model_filename)\n",
    "    else:\n",
    "        print(\"Force load model.\")\n",
    "        model=Sequential()\n",
    "        model.add(Embedding(vocab_size,EMBEDDING_SIZE,input_length=MAX_SENTENCE_LENGTH))\n",
    "        model.add(SpatialDropout1D(DROPOUT))\n",
    "        model.add(Bidirectional(LSTM(HIDDEN_LAYER_SIZE,dropout=DROPOUT,recurrent_dropout=DROPOUT)))\n",
    "        model.add(Dense(1))\n",
    "        model.add(Activation(\"sigmoid\"))\n",
    "        model.compile(loss=\"binary_crossentropy\",optimizer=\"rmsprop\",metrics=[\"accuracy\"])\n",
    "    return model\n",
    "\n",
    "checkpoint=ModelCheckpoint(model_filename, monitor='val_acc', verbose=0, save_best_only=False, mode='auto', period=1)\n",
    "model=load_train_model()\n",
    "history=model.fit(Xtrain,ytrain,batch_size=BATCH_SIZE,epochs=NUM_EPOCHS,validation_data=(Xtest,ytest),callbacks=[checkpoint])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model=load_model(model_filename)\n",
    "model.compile(loss=\"binary_crossentropy\",optimizer=\"rmsprop\",metrics=[\"accuracy\"])\n",
    "predictions=model.predict(X_test)\n",
    "predictions=denormalize_response(predictions)\n",
    "predictions[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_result_filename=\"test_result.csv\"\n",
    "test_result=pd.concat([test['User_ID'],pd.DataFrame(predictions)],axis=1)\n",
    "test_result.columns=['User_ID','Is_Response']\n",
    "test_result.to_csv(test_result_filename,index=False)\n",
    "print(\"File Saved!\")\n",
    "test_result.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
